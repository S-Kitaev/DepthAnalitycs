{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e34d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: D:\\DepthAnalitycs\n",
      "DATA_ROOT: D:\\DepthAnalitycs\\data\\instereo2k_sample\n",
      "LIGHT_WEIGHT: D:\\DepthAnalitycs\\models\\light_weight\n",
      "WEIGHTS_PATH: D:\\DepthAnalitycs\\models\\sceneflow.pth\n",
      "OUTPUT_DIR: D:\\DepthAnalitycs\\results\\train\n",
      "DATASETS_PY D:\\DepthAnalitycs\\datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DepthAnalitycs\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "ROOT = Path('..').resolve()\n",
    "DATA_ROOT = ROOT / 'data' / 'instereo2k_sample'\n",
    "DATASETS_PY = ROOT / 'datasets'\n",
    "MODELS_DIR = ROOT / 'models'\n",
    "LIGHT_WEIGHT = MODELS_DIR / 'light_weight'\n",
    "WEIGHTS_PATH = MODELS_DIR / 'sceneflow.pth'\n",
    "CORE_DIR = LIGHT_WEIGHT / 'core'\n",
    "\n",
    "OUTPUT_DIR = ROOT / 'results' / 'train'\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"LIGHT_WEIGHT:\", LIGHT_WEIGHT)\n",
    "print(\"WEIGHTS_PATH:\", WEIGHTS_PATH)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"DATASETS_PY\", DATASETS_PY)\n",
    "\n",
    "os.chdir('..')\n",
    "sys.path.insert(0, str(LIGHT_WEIGHT))\n",
    "\n",
    "from models.light_weight.core_rt.rt_igev_stereo import IGEVStereo\n",
    "from models.light_weight.evaluate_stereo_rt import *\n",
    "import models.light_weight.core_rt.stereo_datasets as datasets\n",
    "from models.light_weight.core_rt.utils.utils import InputPadder as Padder\n",
    "from datasets.instereo2k import InStereo2KDataset, pil_to_tensor, load_disp_png, resize_pair_and_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8be9770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecb5d7",
   "metadata": {},
   "source": [
    "### Конфиг модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29dbdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace()\n",
    "cfg.name = 'light-igev-train'\n",
    "cfg.logdir = str(OUTPUT_DIR)\n",
    "cfg.device = device\n",
    "cfg.mixed_precision = True\n",
    "cfg.precision_dtype = 'float16'\n",
    "cfg.lr = 2e-4\n",
    "cfg.wdecay = 1e-5\n",
    "cfg.batch_size = 2\n",
    "cfg.num_epochs = 2\n",
    "cfg.num_steps = 20000\n",
    "cfg.train_iters = 12\n",
    "cfg.valid_iters = 12\n",
    "cfg.img_size = [320, 768]\n",
    "cfg.max_disp = 192\n",
    "cfg.n_gru_layers = 1\n",
    "cfg.corr_levels = 2\n",
    "cfg.corr_radius = 4\n",
    "cfg.n_downsample = 2\n",
    "cfg.hidden_dim = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98577486",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(666)\n",
    "np.random.seed(666)\n",
    "random.seed(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc849fc",
   "metadata": {},
   "source": [
    "### Немного упрощенный sequence loss из репозитория модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebae0197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def sequence_loss(agg_pred, iter_preds, disp_gt, valid, loss_gamma=0.9):\n",
    "\n",
    "    n_predictions = len(iter_preds)\n",
    "    assert n_predictions >= 1\n",
    "\n",
    "    mag = torch.sum(disp_gt**2, dim=1).sqrt()\n",
    "    valid_loc = ((valid >= 0.5) & (mag < 192)).unsqueeze(1)\n",
    "    disp_loss = 0.0\n",
    "\n",
    "    disp_loss += 1.0 * F.smooth_l1_loss(agg_pred[valid_loc.bool()], disp_gt[valid_loc.bool()], reduction='mean')\n",
    "    for i in range(n_predictions):\n",
    "        adjusted_loss_gamma = loss_gamma**(15/(n_predictions - 1)) if n_predictions > 1 else 1.0\n",
    "        i_weight = adjusted_loss_gamma**(n_predictions - i - 1)\n",
    "        i_loss = (iter_preds[i] - disp_gt).abs()\n",
    "        disp_loss += i_weight * i_loss[valid_loc.bool()].mean()\n",
    "    epe = torch.sum((iter_preds[-1] - disp_gt)**2, dim=1).sqrt()\n",
    "    epe = epe.view(-1)[valid_loc.view(-1)]\n",
    "    metrics = {\n",
    "        'epe': epe.mean().item() if epe.numel() else float('nan'),\n",
    "        '1px': (epe < 1).float().mean().item() if epe.numel() else float('nan'),\n",
    "        '3px': (epe < 3).float().mean().item() if epe.numel() else float('nan'),\n",
    "    }\n",
    "    return disp_loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ca609",
   "metadata": {},
   "source": [
    "### Даталоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb885cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = InStereo2KDataset(\n",
    "        root_dir=str(DATA_ROOT),\n",
    "        split='train',\n",
    "        val_ratio=0.1,\n",
    "        load_disp=True,\n",
    "        disp_side='left',\n",
    "        disp_divisor=100.0,\n",
    "        resize_hw=(cfg.img_size[0], cfg.img_size[1]))\n",
    "\n",
    "val_ds = InStereo2KDataset(\n",
    "        root_dir=str(DATA_ROOT),\n",
    "        split='val',\n",
    "        val_ratio=0.1,\n",
    "        load_disp=True,\n",
    "        disp_side='left',\n",
    "        disp_divisor=100.0,\n",
    "        resize_hw=(cfg.img_size[0], cfg.img_size[1]))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08171b",
   "metadata": {},
   "source": [
    "### Импрот модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c66011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_4012\\1345366417.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(str(ckpt_path), map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "def strip_prefix(state_dict, prefix='module.'):\n",
    "    if any(k.startswith(prefix) for k in state_dict.keys()):\n",
    "        return {k[len(prefix):] if k.startswith(prefix) else k: v for k, v in state_dict.items()}\n",
    "    return state_dict\n",
    "\n",
    "ckpt_path = WEIGHTS_PATH\n",
    "ckpt = torch.load(str(ckpt_path), map_location='cpu')\n",
    "\n",
    "state = ckpt\n",
    "state = strip_prefix(state, 'module.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b5bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated.\n",
      "Total params (M): 4.17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IGEVStereo(\n",
       "  (update_block): BasicUpdateBlock(\n",
       "    (encoder): BasicMotionEncoder(\n",
       "      (convc1): Conv2d(144, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (convc2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (convd1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (convd2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv): Conv2d(128, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (gru): ConvGRU(\n",
       "      (convz): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (convr): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (convq): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (disp_head): DispHead(\n",
       "      (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_feat_4): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (hnet): Sequential(\n",
       "    (0): BasicConv(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (cnet): BasicConv(\n",
       "    (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (context_zqr_conv): Conv2d(96, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (feature): Feature(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU6(inplace=True)\n",
       "    (block0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block1): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): ReLU6(inplace=True)\n",
       "          (conv_dw): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (bn2): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU6(inplace=True)\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (deconv32_16): Conv2x_IN(\n",
       "      (conv1): BasicConv_IN(\n",
       "        (conv): ConvTranspose2d(160, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (IN): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (conv2): BasicConv_IN(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (IN): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (deconv16_8): Conv2x_IN(\n",
       "      (conv1): BasicConv_IN(\n",
       "        (conv): ConvTranspose2d(192, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (IN): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (conv2): BasicConv_IN(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (deconv8_4): Conv2x_IN(\n",
       "      (conv1): BasicConv_IN(\n",
       "        (conv): ConvTranspose2d(64, 24, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (IN): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "      (conv2): BasicConv_IN(\n",
       "        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (IN): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (conv4): BasicConv_IN(\n",
       "      (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (IN): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (stem_2): Sequential(\n",
       "    (0): BasicConv_IN(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (IN): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (stem_4): Sequential(\n",
       "    (0): BasicConv_IN(\n",
       "      (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (IN): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): InstanceNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (spx): Sequential(\n",
       "    (0): ConvTranspose2d(64, 9, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (spx_2): Conv2x_IN(\n",
       "    (conv1): BasicConv_IN(\n",
       "      (conv): ConvTranspose2d(24, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (IN): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (conv2): BasicConv_IN(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (IN): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (spx_4): Sequential(\n",
       "    (0): BasicConv_IN(\n",
       "      (conv): Conv2d(96, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (IN): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "    (1): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (spx_2_gru): Conv2x(\n",
       "    (conv1): BasicConv(\n",
       "      (conv): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): BasicConv(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (spx_gru): Sequential(\n",
       "    (0): ConvTranspose2d(64, 9, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (conv): BasicConv_IN(\n",
       "    (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (IN): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  )\n",
       "  (desc): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (cost_agg): hourglass(\n",
       "    (conv1): Sequential(\n",
       "      (0): BasicConv(\n",
       "        (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): BasicConv(\n",
       "        (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv(\n",
       "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): BasicConv(\n",
       "        (conv): Conv3d(32, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3_up): BasicConv(\n",
       "      (conv): ConvTranspose3d(48, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2_up): BasicConv(\n",
       "      (conv): ConvTranspose3d(32, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1_up): BasicConv(\n",
       "      (conv): ConvTranspose3d(16, 8, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (agg_0): Sequential(\n",
       "      (0): BasicConv(\n",
       "        (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv(\n",
       "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicConv(\n",
       "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (agg_1): Sequential(\n",
       "      (0): BasicConv(\n",
       "        (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicConv(\n",
       "        (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (feature_att_8): FeatureAtt(\n",
       "      (feat_att): Sequential(\n",
       "        (0): BasicConv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (feature_att_16): FeatureAtt(\n",
       "      (feat_att): Sequential(\n",
       "        (0): BasicConv(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (feature_att_32): FeatureAtt(\n",
       "      (feat_att): Sequential(\n",
       "        (0): BasicConv(\n",
       "          (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (feature_att_up_16): FeatureAtt(\n",
       "      (feat_att): Sequential(\n",
       "        (0): BasicConv(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (feature_att_up_8): FeatureAtt(\n",
       "      (feat_att): Sequential(\n",
       "        (0): BasicConv(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Conv3d(8, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = cfg\n",
    "\n",
    "model = IGEVStereo(args)\n",
    "print(\"Model instantiated.\")\n",
    "print(\"Total params (M): %.2f\" % (sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6))\n",
    "\n",
    "model.load_state_dict(state, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e01754",
   "metadata": {},
   "source": [
    "### Оптимизатор и логгер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabe9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.wdecay, eps=1e-8)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=cfg.lr, \n",
    "                                          total_steps=max(1, cfg.num_epochs * (len(train_loader) if train_loader is not None else 1)), \n",
    "                                          pct_start=0.01, \n",
    "                                          cycle_momentum=False)\n",
    "\n",
    "class DummyScaler:\n",
    "        def scale(self, x): return x\n",
    "        def unscale_(self, opt): pass\n",
    "        def step(self, opt): opt.step()\n",
    "        def update(self): pass\n",
    "scaler = DummyScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f6aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLogger:\n",
    "    def __init__(self, out_dir: Path):\n",
    "        self.out_dir = Path(out_dir)\n",
    "        self.out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.csv_path = self.out_dir / 'train_log.csv'\n",
    "        self.writer = SummaryWriter(log_dir=str(self.out_dir))\n",
    "        self.step = 0\n",
    "        with open(self.csv_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['step','epoch','loss','epe','1px','3px','lr'])\n",
    "            writer.writeheader()\n",
    "    def log_step(self, epoch, loss, metrics, lr):\n",
    "        row = {'step': self.step, 'epoch': epoch, 'loss': float(loss), 'epe': metrics.get('epe', float('nan')), '1px': metrics.get('1px', float('nan')), '3px': metrics.get('3px', float('nan')), 'lr': lr}\n",
    "        with open(self.csv_path, 'a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=list(row.keys()))\n",
    "            writer.writerow(row)\n",
    "\n",
    "        self.writer.add_scalar('train/loss', float(loss), self.step)\n",
    "        self.writer.add_scalar('train/epe', float(metrics.get('epe', 0.0)), self.step)\n",
    "        self.writer.add_scalar('train/1px', float(metrics.get('1px', 0.0)), self.step)\n",
    "        self.writer.add_scalar('train/3px', float(metrics.get('3px', 0.0)), self.step)\n",
    "        self.writer.add_scalar('train/lr', lr, self.step)\n",
    "        self.step += 1\n",
    "    def close(self):\n",
    "        self.writer.close()\n",
    "\n",
    "logger = TrainLogger(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec0a21",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3b4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, cfg, device):\n",
    "    model.eval()\n",
    "    tot_epe = []\n",
    "    tot_1px = []\n",
    "    tot_3px = []\n",
    "    with torch.no_grad():\n",
    "        for _, *data_blob in dataloader:\n",
    "            try:\n",
    "                image1, image2, disp_gt, valid = [x.to(device) for x in data_blob]\n",
    "            except Exception:\n",
    "                batch = _ if isinstance(_, dict) else None\n",
    "                continue\n",
    "            inp1 = (image1 * 255.0)\n",
    "            inp2 = (image2 * 255.0)\n",
    "\n",
    "            padder = Padder(inp1.shape, divis_by=32)\n",
    "            inp1_p, inp2_p = padder.pad(inp1, inp2)\n",
    "            out = model(inp1_p, inp2_p, iters=cfg.valid_iters, test_mode=True)\n",
    "            out = padder.unpad(out)\n",
    "            if out.ndim == 4 and out.shape[1] == 1:\n",
    "                out = out.squeeze(1)\n",
    "            pred = out[:,0,:,:] if out.ndim==4 else out\n",
    "            # pred (B,H,W), disp_gt (B,1,H,W)\n",
    "            if disp_gt is not None:\n",
    "                pred_interp = pred\n",
    "                gt = disp_gt\n",
    "                valid_mask = (valid >= 0.5).float()\n",
    "                epe = torch.abs(pred_interp - gt).view(-1)\n",
    "                valid_flat = valid_mask.view(-1).bool()\n",
    "                if valid_flat.any():\n",
    "                    epe = epe[valid_flat]\n",
    "                    tot_epe.append(epe.mean().item())\n",
    "                    tot_1px.append((epe < 1.0).float().mean().item())\n",
    "                    tot_3px.append((epe < 3.0).float().mean().item())\n",
    "    model.train()\n",
    "    return {'epe': np.nanmean(tot_epe) if tot_epe else float('nan'),\n",
    "            '1px': np.nanmean(tot_1px) if tot_1px else float('nan'),\n",
    "            '3px': np.nanmean(tot_3px) if tot_3px else float('nan')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = float('inf')\n",
    "global_step = 0\n",
    "save_dir = Path(cfg.logdir)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, cfg.num_epochs + 1):\n",
    "    epoch_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_metrics = {'epe':0.0, '1px':0.0, '3px':0.0}\n",
    "    n_batches = 0\n",
    "\n",
    "    for i_batch, batch in enumerate(train_loader):\n",
    "        if isinstance(batch, dict):\n",
    "            image1 = batch['left'].to(device)\n",
    "            image2 = batch['right'].to(device)\n",
    "            disp_gt = batch.get('disp', None)\n",
    "            valid = batch.get('mask', None)\n",
    "            if disp_gt is not None:\n",
    "                disp_gt = disp_gt.to(device).unsqueeze(1)\n",
    "            if valid is not None:\n",
    "                valid = valid.to(device)\n",
    "        else:\n",
    "            try:\n",
    "                if len(batch) == 4:\n",
    "                    image1, image2, disp_gt, valid = batch\n",
    "                    image1 = image1.to(device); image2 = image2.to(device)\n",
    "                    disp_gt = disp_gt.to(device).unsqueeze(1)\n",
    "                    valid = valid.to(device)\n",
    "                else:\n",
    "                    _, *data_blob = batch\n",
    "                    image1, image2, disp_gt, valid = [x.to(device) for x in data_blob]\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inp1 = (image1 * 255.0)\n",
    "        inp2 = (image2 * 255.0)\n",
    "\n",
    "        padder = Padder(inp1.shape, divis_by=32)\n",
    "        inp1_p, inp2_p = padder.pad(inp1, inp2)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=cfg.mixed_precision):\n",
    "            agg_pred, iter_preds = model(inp1_p, inp2_p, iters=cfg.train_iters)\n",
    "            loss, metrics = sequence_loss(agg_pred, iter_preds, disp_gt, valid)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if isinstance(scheduler, optim.lr_scheduler.OneCycleLR):\n",
    "            try:\n",
    "                scheduler.step()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_metrics['epe'] += metrics.get('epe', 0.0)\n",
    "        running_metrics['1px'] += metrics.get('1px', 0.0)\n",
    "        running_metrics['3px'] += metrics.get('3px', 0.0)\n",
    "        n_batches += 1\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 20 == 0:\n",
    "            avg_loss = running_loss / n_batches\n",
    "            avg_metrics = {k: running_metrics[k]/n_batches for k in running_metrics}\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            logger.log_step(epoch, avg_loss, avg_metrics, lr)\n",
    "\n",
    "    val_metrics = {}\n",
    "    if val_loader is not None:\n",
    "        val_metrics = validate(model, val_loader, cfg, device)\n",
    "        logger.writer.add_scalar('val/epe', val_metrics['epe'], epoch)\n",
    "        logger.writer.add_scalar('val/1px', val_metrics['1px'], epoch)\n",
    "        logger.writer.add_scalar('val/3px', val_metrics['3px'], epoch)\n",
    "\n",
    "    # save\n",
    "    ckpt_path = save_dir / f\"{cfg.name}_epoch{epoch}.pth\"\n",
    "    to_save = model.state_dict()\n",
    "    torch.save({'epoch': epoch, 'state_dict': to_save, 'optimizer': optimizer.state_dict()}, str(ckpt_path))\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch {epoch} done in {epoch_time:.1f}s | loss={running_loss/n_batches:.4f} | train_epe={running_metrics['epe']/n_batches:.4f} | val_epe={val_metrics.get('epe','nan'):.4f}\")\n",
    "\n",
    "# finish\n",
    "logger.close()\n",
    "print(\"Training finished. Checkpoints & logs at\", save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
